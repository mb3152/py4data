{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Machine Learning: Image Classifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import (a few) Modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from scipy import ndimage\n",
      "from scipy.stats import mode\n",
      "from skimage import data\n",
      "from skimage import data, img_as_float\n",
      "from skimage import filter\n",
      "from skimage import io\n",
      "from skimage import measure\n",
      "from skimage.color.colorconv import rgb2gray\n",
      "from skimage.color.colorconv import gray2rgb\n",
      "from skimage.feature import daisy\n",
      "from skimage.feature import peak_local_max\n",
      "from skimage.filter import rank\n",
      "from skimage.filter import vsobel, hsobel, rank\n",
      "from skimage.measure import structural_similarity as ssim\n",
      "from skimage.morphology import watershed, disk\n",
      "from skimage.util import img_as_ubyte\n",
      "from sklearn import cross_validation, metrics\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "import cPickle as pickle\n",
      "import Image\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "\"Custom\" Features; I took some complex features and extracted a single value out of them. \n",
      "We will extract these from the images in the training set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def num_daisy_desc(img):\n",
      "    try: \n",
      "        img = rgb2gray(img)\n",
      "        descs, descs_img = daisy(img, step=180, radius=58, rings=2, histograms=6, orientations=8, visualize=True)\n",
      "        descs_num = descs.shape[0] * descs.shape[1]\n",
      "        return descs_num\n",
      "    except ValueError:\n",
      "        return 0\n",
      "\n",
      "def num_contours(img):\n",
      "    contours = measure.find_contours(img, 0.8)\n",
      "    x = len(contours)\n",
      "    return x\n",
      "\n",
      "def num_local_max(img):\n",
      "    img = img_as_float(img)\n",
      "    image_max = ndimage.maximum_filter(img, size=20, mode='constant')\n",
      "    coordinates = peak_local_max(img, min_distance=20)\n",
      "    x=len(coordinates)\n",
      "    return x\n",
      "\n",
      "def mse(x, y):\n",
      "    return np.linalg.norm(x - y)\n",
      "\n",
      "def img_noise(img):\n",
      "    img = rgb2gray(img)\n",
      "    img = img_as_float(img)\n",
      "    rows, cols = img.shape\n",
      "    noise = np.ones_like(img) * 0.2 * (img.max() - img.min())\n",
      "    noise[np.random.random(size=noise.shape) > 0.5] *= -1\n",
      "    img_noise = img + noise\n",
      "    x = np.mean(img_noise)\n",
      "    return x\n",
      "\n",
      "def img_const(img):\n",
      "    img = rgb2gray(img)\n",
      "    img = img_as_float(img)\n",
      "    rows, cols = img.shape\n",
      "    noise = np.ones_like(img) * 0.2 * (img.max() - img.min())\n",
      "    noise[np.random.random(size=noise.shape) > 0.5] *= -1\n",
      "    img_noise = img + noise\n",
      "    img_const = img + abs(noise)\n",
      "    x = np.mean(img_const)\n",
      "    return x\n",
      "\n",
      "def num_continuous_regions(img):\n",
      "    image = img_as_ubyte(img)\n",
      "    # denoise image\n",
      "    denoised = rank.median(image, disk(2))\n",
      "    # find continuous region (low gradient) --> markers\n",
      "    markers = rank.gradient(denoised, disk(5)) < 10\n",
      "    markers = ndimage.label(markers)[0]\n",
      "    x = len(markers)\n",
      "    return x\n",
      "\n",
      "def num_edges(im):\n",
      "    im = rgb2gray(im)\n",
      "    im = ndimage.rotate(im, 15, mode='constant')\n",
      "    im = ndimage.gaussian_filter(im, 4)\n",
      "    im += 0.2 * np.random.random(im.shape) \n",
      "    edges = filter.canny(im, sigma=3)\n",
      "    x = len(edges)\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function to extract features from images in training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_features(image):\n",
      "    \"\"\"Return an array of 22--features extracted from image.\"\"\"\n",
      "    # Make sure the image is in RGB format to begin with.\n",
      "    if len(image.shape) == 2:\n",
      "        image = gray2rgb(image)\n",
      "    #setup a standard image size; this will distort some images but will get everything into the same shape\n",
      "    features = np.empty(22)\n",
      "    # Split out the color channels.\n",
      "    r_channel = image[..., 0]\n",
      "    g_channel = image[..., 1]\n",
      "    b_channel = image[..., 2]\n",
      "    # Convert the image to grayscale and get the vertical and horizontal edges.\n",
      "    gray_image = rgb2gray(image)\n",
      "    vert_edges = vsobel(gray_image)\n",
      "    horiz_edges = hsobel(gray_image)\n",
      "    # Segment the image.  This code is copied from the \"Markers for watershed transform\" scikit-image example.\n",
      "    denoised = rank.median(img_as_ubyte(gray_image), disk(2))\n",
      "    markers = ndimage.label(rank.gradient(denoised, disk(5)) < 10)[0]\n",
      "    gradient = rank.gradient(denoised, disk(2))\n",
      "    labels = watershed(gradient, markers)\n",
      "    # Compute the features.\n",
      "    features[0] = r_channel.std()\n",
      "    features[1] = g_channel.std()\n",
      "    features[2] = b_channel.std()\n",
      "    features[3] = r_channel.mean()\n",
      "    features[4] = g_channel.mean()\n",
      "    features[5] = b_channel.mean()\n",
      "    features[6] = image.shape[0]\n",
      "    features[7] = image.shape[1]\n",
      "    features[8] = np.corrcoef(r_channel.flatten(), g_channel.flatten())[0, 1]\n",
      "    features[9] = np.corrcoef(r_channel.flatten(), b_channel.flatten())[0, 1]\n",
      "    features[10] = np.corrcoef(b_channel.flatten(), g_channel.flatten())[0, 1]\n",
      "    # The next feature is (roughly) the proportion of all pixels in the image that are part of a vertical edge.\n",
      "    features[11] = len(vert_edges[vert_edges > 0.1]) / float(len(vert_edges.flatten()))\n",
      "    # The next feature is (roughly) the proportion of all pixels in the image that are part of a horizontal edge.\n",
      "    features[12] = len(horiz_edges[horiz_edges > 0.1]) / float(len(horiz_edges.flatten()))\n",
      "    # The next feature is the number of objects found by segmentation.\n",
      "    features[13] = len(np.unique(labels))\n",
      "    # The next feature is the size of the largest object, as a proportion of the total image.\n",
      "    val, count = mode(labels, axis=None)\n",
      "    features[14] = count[0] / len(labels.flatten())\n",
      "    features[15] = num_daisy_desc(gray_image)\n",
      "    features[16] = num_contours(gray_image)\n",
      "    features[17] = num_local_max(image)\n",
      "    features[18] = img_noise(gray_image)\n",
      "    features[19] = img_const(gray_image)\n",
      "    features[20] = num_continuous_regions(gray_image)\n",
      "    features[21] = num_edges(gray_image)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import the images and pass them through the feature extraction, but only if this hasn't been done"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_dir = 'validation_images/'\n",
      "categories = [c for c in os.listdir(top_dir)]\n",
      "#clean up categories. this might be different depending on what hidden files exist! \n",
      "categories = categories[0:]\n",
      "fin_categories = []\n",
      "for i in categories:\n",
      "    if i != 'Icon\\r' and not i.startswith('.'):\n",
      "        fin_categories.append(i)\n",
      "\n",
      "cat2int = {cat: i for i, cat in enumerate(fin_categories) if not cat.startswith('.')}\n",
      "int2cat = {v: k for k, v in cat2int.iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fin_categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['airplanes',\n",
        " 'bat',\n",
        " 'bear',\n",
        " 'blimp',\n",
        " 'camel',\n",
        " 'comet',\n",
        " 'conch',\n",
        " 'cormorant',\n",
        " 'crab',\n",
        " 'dog',\n",
        " 'dolphin',\n",
        " 'duck',\n",
        " 'elephant',\n",
        " 'elk',\n",
        " 'frog',\n",
        " 'galaxy',\n",
        " 'giraffe',\n",
        " 'goat',\n",
        " 'goldfish',\n",
        " 'goose',\n",
        " 'gorilla',\n",
        " 'helicopter',\n",
        " 'horse',\n",
        " 'hot-air-balloon',\n",
        " 'hummingbird',\n",
        " 'iguana',\n",
        " 'kangaroo',\n",
        " 'killer-whale',\n",
        " 'leopards',\n",
        " 'llama',\n",
        " 'mars',\n",
        " 'mussels',\n",
        " 'octopus',\n",
        " 'ostrich',\n",
        " 'owl',\n",
        " 'penguin',\n",
        " 'porcupine',\n",
        " 'raccoon',\n",
        " 'saturn',\n",
        " 'skunk',\n",
        " 'snail',\n",
        " 'snake',\n",
        " 'speed-boat',\n",
        " 'starfish',\n",
        " 'swan',\n",
        " 'teddy-bear',\n",
        " 'toad',\n",
        " 'triceratops',\n",
        " 'unicorn',\n",
        " 'zebra']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert len(fin_categories) == 50\n",
      "#if this fails, it means that there are hidden files being treated as categories that I was not able to catch."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#here is where we import the feature array for the new images, or make it if it doesn't exist. It should exist! \n",
      "try:\n",
      "    data = np.load('datafile_test.npy')\n",
      "    print 'Loaded feature data'\n",
      "    file_paths = []\n",
      "    i = 0\n",
      "    for category in os.listdir(top_dir):\n",
      "        # Ignore hidden files and wierd directories.\n",
      "        if not category.startswith('.') and category != 'Icon\\r':\n",
      "            for im_file in os.listdir('/'.join([top_dir, category])):\n",
      "                if not im_file.startswith('.') and im_file != 'Icon\\r':\n",
      "                    file_path = '/'.join([top_dir, category, im_file])\n",
      "                    file_paths.append(file_path)\n",
      "                    i += 1\n",
      "except IOError:\n",
      "    print 'Making feature data...this will be a while'\n",
      "    data = np.empty((4244, 23))\n",
      "    file_paths = []\n",
      "    i = 0\n",
      "    for category in os.listdir(top_dir):\n",
      "        # Ignore hidden files and wierd directories.\n",
      "        if not category.startswith('.') and category != 'Icon\\r':\n",
      "            for im_file in os.listdir('/'.join([top_dir, category])):\n",
      "                if not im_file.startswith('.') and im_file != 'Icon\\r':\n",
      "                    file_path = '/'.join([top_dir, category, im_file])\n",
      "                    image = io.imread(file_path)\n",
      "                    data[i, :-1] = extract_features(image)\n",
      "                    data[i, -1] = cat2int[category]\n",
      "                    file_paths.append(file_path)\n",
      "                    i += 1\n",
      "    np.save('datafile_test',data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded feature data\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Sanity check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Let's see how these features perform."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shuffle the rows of data.\n",
      "np.random.shuffle(data)\n",
      "rfc = RandomForestClassifier(n_estimators=100, n_jobs = 1, compute_importances=True)\n",
      "# Classify using k-folds cross validation, with k = 5.\n",
      "k_fold = cross_validation.KFold(n=len(file_paths), n_folds=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/Maxwell/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.py:783: DeprecationWarning: Setting compute_importances is no longer required as version 0.14. Variable importances are now computed on the fly when accessing the feature_importances_ attribute. This parameter will be removed in 0.16.\n",
        "  DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "How does our classifier perform?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Average the CV score across folds.\n",
      "np.mean(cross_validation.cross_val_score(rfc, data[:, :-1], data[:, -1], cv=k_fold))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.63166259711431749"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Doesn't seem super accurate, but what would chance be?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chance = 1.0 / len(cat2int.keys())\n",
      "assert chance == 0.02\n",
      "#if this fails you have too many categories or something worse went wrong."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Not bad, but how does it do when categories are randomly assigned to feature arrays?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = data[:, -1].copy()\n",
      "np.random.shuffle(Y)\n",
      "np.mean(cross_validation.cross_val_score(rfc, data[:, :-1], Y, cv=k_fold))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.5487547169811321"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Roughly chance, where it should be."
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "What were our good features?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Refit the classifier with all the data, to prepare it for testing on a new validation set.\n",
      "rfc.fit(data[:, :-1], data[:, -1])\n",
      "# These are the indices of the three most important features (see extract_features for definitions), from most \n",
      "# important to least.\n",
      "print np.argsort(rfc.feature_importances_)[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[11 20 21  6  7]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Only run this line if changes have been made and you want to save out a new classifier. Make sure name here and name in forest= in def final_classifier are the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pickle.dump(rfc, open('trained_classifier.p', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classify New Images"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Simply run \"final_classifier(x)\" with x as the path to your images that you want to classify"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_results():\n",
      "    results = open('results.txt')\n",
      "    lines = results.readlines()\n",
      "    i = 0\n",
      "    while i < len(lines):\n",
      "        print lines[i]\n",
      "        i = i+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_final_classifier(path_to_images):\n",
      "    ###simply pass the function the directory where you keep all your images, without sub directories please.###\n",
      "    ###it will save out a file called 'results.txt', as well as print the results out###\n",
      "    ###make sure you are using the right name for the forest=\n",
      "    name = path_to_images[:-1]\n",
      "    out_file='%s_results.txt' %(name)\n",
      "    forest='trained_classifier.p'\n",
      "    classifier = pickle.load(open(forest, 'r'))\n",
      "    with open(out_file, 'w') as f:\n",
      "        f.write('filename\\tpredicted_class\\n' + '-' * 30 + '\\n')\n",
      "    for im_file in os.listdir(path_to_images):\n",
      "        try:\n",
      "            image = io.imread(''.join([path_to_images, im_file]))\n",
      "        except IOError:\n",
      "            continue\n",
      "        X = extract_features(image)\n",
      "        guess = int2cat[classifier.predict(X)[0]]\n",
      "        with open(out_file, 'a') as f:\n",
      "            im_file = os.path.splitext(im_file)\n",
      "            im_file = im_file[0]\n",
      "            f.write('\\t'.join([im_file, guess, '\\n']))\n",
      "    print_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Try it with the valedation images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data2= data[:,:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = pickle.load(open('trained_classifier.p','r') )\n",
      "pred = clf.predict(data2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "rfor_accuracy_score = metrics.accuracy_score(Yte, pred) \n",
      "# create and save the confusion matrix\n",
      "confmat = sklearn.metrics.confusion_matrix(Yte, pred)\n",
      "plt.imshow(confmat, interpolation=\"nearest\", origin=\"upper\")\n",
      "plt.savefig(\"confusion_matrix.pdf\")\n",
      "plt.close(\"all\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_file = file(\"final_results.txt\", \"w\")\n",
      "results_file.write(\"Predicted image classes for Maxwell Bertolero's classifier\\n\")\n",
      "results_file.write(\"-----------------------------------------\\n\")\n",
      "results_file.write(\"Accuracy score: \" + str(float(match) / float(miss)) + '\\n')\n",
      "results_file.write(\"-----------------------------------------\\n\")\n",
      "miss = 0\n",
      "match = 0\n",
      "real=data[:,-1:]\n",
      "assert len(real) == len(pred)\n",
      "for guess, realness in zip(pred, real):\n",
      "    try:\n",
      "        name = int2cat[guess]\n",
      "    except KeyError:\n",
      "        name = 'zebra'\n",
      "    if guess == realness:\n",
      "        results_file.write('Match' + ' on ' + name + '\\n')\n",
      "        match = match + 1 \n",
      "    else: \n",
      "        results_file.write('Non-Match' + ' on '  + name + '\\n')\n",
      "        miss = miss + 1 \n",
      "results_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "done!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}